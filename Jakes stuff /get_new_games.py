{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "764adcd0-7f1b-45a9-b0e1-dc25aaec6d76",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (874749836.py, line 158)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/pb/9nrds4y576x41j1jw01gnkc40000gn/T/ipykernel_14527/874749836.py\"\u001b[0;36m, line \u001b[0;32m158\u001b[0m\n\u001b[0;31m    new_games = preformater.preformat_games()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from time import time, sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from NBADataPreformater import NBADataPreformater\n",
    "from utils import *\n",
    "\n",
    "USER_AGENTS = [\n",
    "    # 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "    # 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "    # 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "    # 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:70.0) Gecko/20100101 Firefox/70.0',\n",
    "    # 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) Gecko/20100101 Firefox/55.0'\n",
    "]\n",
    "# USER_AGENTS = [\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.110 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) Gecko/20100101 Firefox/55.0'),  # firefox\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.91 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.89 Safari/537.36'),  # chrome\n",
    "#     ('Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.108 Safari/537.36'),  # chrome\n",
    "# ]\n",
    "\n",
    "HEADERS = {\n",
    "    # 'Host': 'i.cdn.turner.com',\n",
    "    # \"Host\": \"httpbin.org\",\n",
    "    # 'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:70.0) Gecko/20100101 Firefox/70.0',\n",
    "    'Referer': 'https://www.nba.com/stats/',\n",
    "    'Origin': 'https://www.nba.com',\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Language': 'en-GB,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Pragma': 'no-cache',\n",
    "    'Cache-Control': 'no-cache',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('----- START -----')\n",
    "    t0 = time()\n",
    "\n",
    "    # Update this line if the data directory is not in the parent directory\n",
    "    path = os.path.dirname(os.path.abspath(__file__)) + '/../data/'\n",
    "\n",
    "    # Get old games data to find out the last date that the script was executed\n",
    "    try:\n",
    "        old_games = pd.read_csv(path + 'games.csv')\n",
    "    except:\n",
    "        raise Exception(\n",
    "            'games.csv should be in the data/ directory, if you don\\'t have the current games.csv, ' +\n",
    "            'just download it from https://www.kaggle.com/nathanlauga/nba-games'\n",
    "        )\n",
    "\n",
    "    max_date = old_games['GAME_DATE_EST'].max()\n",
    "\n",
    "    if max_date == get_date(1):\n",
    "        print('Last update is yesterday : end script now.')\n",
    "        return\n",
    "\n",
    "    print('Last updated date : ', str(max_date))\n",
    "\n",
    "    # Load old datasets\n",
    "    old_ranking = pd.read_csv(path + 'ranking.csv')\n",
    "    old_games_details = pd.read_csv(path + 'games_details.csv')\n",
    "\n",
    "    # Dataset to retrieve from api\n",
    "    datasets = [\n",
    "        'GameHeader', 'LineScore', 'EastConfStandingsByDay',\n",
    "        'WestConfStandingsByDay'\n",
    "    ]\n",
    "    ignore_keys = ['date']\n",
    "\n",
    "    # init dictionnary to collect data\n",
    "    dfs = {}\n",
    "    for dataset in datasets + ignore_keys:\n",
    "        dfs[dataset] = list()\n",
    "\n",
    "    # Be sure this file is the save of the current run\n",
    "    save_path = 'games.sav'\n",
    "    if os.path.exists(save_path):\n",
    "        dfs = joblib.load(save_path)\n",
    "        min_date_already_saved = min(dfs['date'])\n",
    "    else:\n",
    "        min_date_already_saved = '2100-01-01'\n",
    "\n",
    "    # Use a for loop to avoid while(True) infinite loop\n",
    "    for i in range(1, 10000):\n",
    "        date = get_date(i)\n",
    "\n",
    "        if date <= max_date:\n",
    "            break\n",
    "        elif date >= min_date_already_saved:\n",
    "            continue\n",
    "\n",
    "        url = 'https://stats.nba.com/stats/scoreboardV2?DayOffset=0&LeagueID=00&gameDate=' + date\n",
    "\n",
    "        print(url)\n",
    "\n",
    "        # update user agents\n",
    "        HEADERS['User-Agent'] = np.random.choice(USER_AGENTS)\n",
    "        # print(HEADERS['User-Agent'])\n",
    "\n",
    "        game_day_dfs = get_data(url=url,\n",
    "                                datasets_name=datasets,\n",
    "                                headers=HEADERS)\n",
    "        game_day_dfs['date'] = date\n",
    "        sleep(0.2)\n",
    "\n",
    "        # print(game_day_dfs['GameHeader'])\n",
    "        print('There are %i games this day' % len(game_day_dfs['GameHeader']))\n",
    "\n",
    "        for dataset in game_day_dfs.keys():\n",
    "            dfs[dataset].append(game_day_dfs[dataset])\n",
    "\n",
    "        joblib.dump(dfs, save_path)\n",
    "\n",
    "    # convert to pandas DataFrame\n",
    "    for dataset in dfs.keys():\n",
    "        if dataset in ignore_keys:\n",
    "            continue\n",
    "        dfs[dataset] = pd.concat(dfs[dataset])\n",
    "        print(dataset, dfs[dataset].shape)\n",
    "\n",
    "    header_cols = [\n",
    "        'GAME_DATE_EST', 'GAME_ID', 'GAME_STATUS_TEXT', 'HOME_TEAM_ID',\n",
    "        'VISITOR_TEAM_ID', 'SEASON'\n",
    "    ]\n",
    "    linescore_cols = [\n",
    "        'GAME_ID', 'TEAM_ID', 'PTS', 'FG_PCT', 'FT_PCT', 'FG3_PCT', 'AST',\n",
    "        'REB'\n",
    "    ]\n",
    "\n",
    "    # Get wanted datasets with wanted columns\n",
    "    west_ranking = dfs['WestConfStandingsByDay']\n",
    "    east_ranking = dfs['EastConfStandingsByDay']\n",
    "    games_header = dfs['GameHeader'][header_cols]\n",
    "    line_score = dfs['LineScore'][linescore_cols]\n",
    "\n",
    "    del dfs\n",
    "\n",
    "    # Preformat NBA data\n",
    "    print('Preformat nba data')\n",
    "HEAD\n",
    "preformater = NBADataPreformater(games_header, line_score, west_ranking,\n",
    "                                     east_ranking, path)\n",
    "\n",
    "preformater = NBADataPreformater(\n",
    "        games_header, line_score, west_ranking, east_ranking,path)\n",
    "\"8379061a7ecfe3fe8edd118f730ebe5c659245f3\"\n",
    "    new_games = preformater.preformat_games()\n",
    "    new_ranking = preformater.preformat_ranking()\n",
    "\n",
    "    del games_header, line_score, west_ranking, east_ranking\n",
    "\n",
    "    dfs_details = list()\n",
    "\n",
    "    # Be sure this file is the save of the current run\n",
    "    save_details_path = 'games_details.sav'\n",
    "    game_details_already_saved = []\n",
    "\n",
    "    if os.path.exists(save_details_path):\n",
    "        dfs_details = joblib.load(save_details_path)\n",
    "        game_details_already_saved = pd.concat(dfs_details)['GAME_ID'].unique()\n",
    "\n",
    "    # Retrieve game detail\n",
    "    print('Retrieve new games details, # of games to get : ',\n",
    "          str(len(new_games['GAME_ID'])))\n",
    "    for game_id in new_games['GAME_ID']:\n",
    "        if game_id in game_details_already_saved:\n",
    "            continue\n",
    "\n",
    "        # HEADERS['User-Agent'] = np.random.choice(USER_AGENTS)\n",
    "        HEADERS[\n",
    "            'User-Agent'] = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) Gecko/20100101 Firefox/55.0'\n",
    "\n",
    "        df = get_game_detail(game_id, headers=HEADERS)\n",
    "        if len(df) == 0:\n",
    "            print('No data found')\n",
    "\n",
    "        dfs_details.append(df)\n",
    "\n",
    "        joblib.dump(dfs_details, save_details_path)\n",
    "\n",
    "    new_games_details = pd.concat(dfs_details)\n",
    "\n",
    "    # Merge old and new dataframe\n",
    "    print('Merging old and new datasets')\n",
    "    ranking = merge_news_old(new_ranking, old_ranking)\n",
    "    games = merge_news_old(new_games, old_games)\n",
    "    games_details = merge_news_old(new_games_details, old_games_details)\n",
    "\n",
    "    games['GAME_ID'] = pd.to_numeric(games['GAME_ID'])\n",
    "    games['GAME_DATE_EST'] = pd.to_datetime(games['GAME_DATE_EST'])\n",
    "    games_details['GAME_ID'] = pd.to_numeric(games_details['GAME_ID'])\n",
    "    ranking['STANDINGSDATE'] = pd.to_datetime(ranking['STANDINGSDATE'])\n",
    "\n",
    "    # Save merge datasets\n",
    "    print('Save new datasets to csv into ', path)\n",
    "    today = get_date(0)\n",
    "    games.to_csv(path + 'games.csv', index=False)\n",
    "    games_details.to_csv(path + 'games_details.csv', index=False)\n",
    "    ranking.to_csv(path + 'ranking.csv', index=False)\n",
    "\n",
    "    print('Delete tmp saved files')\n",
    "    os.remove(save_path)\n",
    "    os.remove(save_details_path)\n",
    "\n",
    "    print('-----  END  ----- execution time : %.2fs' % (time() - t0))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3ce97-f5c3-437c-b4c9-7ffb20e12386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
